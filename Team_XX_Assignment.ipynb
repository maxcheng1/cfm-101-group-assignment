{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Assignment\n",
    "### Team Number: 3\n",
    "### Team Member Names: Derek Tan, Jeff Peng, Yuqian Lin\n",
    "### Team Strategy Chosen: SAFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "Our portfolio optimization strategy involves the use and implementation of the Modern Portfolio Theory (MPT) and analysis of the Efficient Frontier graphs. The objective of the portfolio optimization strategy is to maximize the portfolio return while maintaining the minimum portfolio risk. \n",
    "\n",
    "Modern Portfolio Theory states that since it is assumed that all investors are risk-adverse, when considering the possible portfolio allocation strategies, the investor will prefer the portfolio that maximizes the possible return while maintaining a given amount of risk. \n",
    "\n",
    "The Efficient Frontier (EF), the core of our strategy, was introduced by Nobel Laureate Harry Markowitz and is fundamental to MPT. The EP is a graph that illustrates all possible portfolios portfolio allocation distributions. The x-axis represents the volatility/risk of the portfolio, while the y-axis represents the expected return of the portfolio.\n",
    "\n",
    "The Efficient Frontier shows the optimized portfolios that offer the highest expected return for a given level of risk and the lowest level of risk for a given level of expected return.\n",
    "\n",
    "An example of the an Efficient Frontier graph is shown below:\n",
    "\n",
    "![EF Graph](ef.png)\n",
    "\n",
    "As seen from the graph, the light blue dot is the portfolio that takes on the highest level of risk coupled with the highest degree of return. Conversely, the left-most purple dot depicts the portfolio that with the lowest level of risk and lowest given level of return. Typically, risk-seeking investors will select portfolios that lie on the right end as they yield a higher return for a high level of risk. In our group's case, we chose the \"safe\" strategy, and thus will be selecting the portfolio on the left-end of the graph as it yields a lower return for a lower level of risk.\n",
    "\n",
    "We will be discussing more about how we graphed each portfolio along the EF graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing our strategy, we have to filter out any invalid stock tickers. That is, any tickers that are not traded in USD and tickers with an average daily volume of less than 10000 shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df = pd.read_csv('Tickers.csv', index_col=False)\n",
    "results = list(ticker_df.iloc[:, 0])\n",
    "results.insert(0, ticker_df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter list of tickers for valid tickers\n",
    "\n",
    "# filter_tickers(list_of_tickers) produces a list of tickers\n",
    "#   of all tickers in [list_of_tickers] that have a daily \n",
    "#   average volume above 10 000 shares and are traded in USD\n",
    "\n",
    "\"\"\"\n",
    "Params:\n",
    "    list_of_tickers (listof Str): Unfiltered original list of tickers\n",
    "\"\"\"\n",
    "\n",
    "# def filter_tickers(list_of_tickers):\n",
    "    \n",
    "#     start_date = \"2021-07-02\"\n",
    "#     end_date = \"2021-10-22\"\n",
    "\n",
    "#     for i in range(len(list_of_tickers)):\n",
    "#         ticker = yf.Ticker(list_of_tickers[i])\n",
    "#         ticker_hist = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "#         if ticker_hist[\"Volume\"].mean() < 10000 or ticker.info[\"currency\"] != \"USD\":\n",
    "#             list_of_tickers.remove(list_of_tickers[i])\n",
    "\n",
    "#     return list_of_tickers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters_nan(ticker_list) filters out stocks with invalid prices, that is stocks with NaN values.\n",
    "#It then produces a list of these filtered tickers\n",
    "\n",
    "\"\"\"\n",
    "Params:\n",
    "    ticker_list (listof Str): Unfiltered original list of tickers\n",
    "\"\"\"\n",
    "\n",
    "def filters_nan(ticker_list):\n",
    "    start_date = \"2018-01-02\"\n",
    "    end_date = \"2021-10-31\"\n",
    "    no_nan = []\n",
    "    \n",
    "    for i in range (ticker_list.shape[1]):\n",
    "        if ticker_list.iloc[:, i].isna().sum() < len(ticker_list)-209:\n",
    "            no_nan.append((ticker_list.columns)[i])\n",
    "        \n",
    "    return no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  62 of 62 completed\n",
      "\n",
      "4 Failed downloads:\n",
      "- CELG: No data found, symbol may be delisted\n",
      "- AGN: No data found, symbol may be delisted\n",
      "- PCLN: No data found for this date range, symbol may be delisted\n",
      "- RTN: No data found, symbol may be delisted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>AGN</th>\n",
       "      <th>AIG</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>...</th>\n",
       "      <th>SPG</th>\n",
       "      <th>T</th>\n",
       "      <th>TD.TO</th>\n",
       "      <th>TGT</th>\n",
       "      <th>TWX</th>\n",
       "      <th>TXN</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>41.188160</td>\n",
       "      <td>81.059563</td>\n",
       "      <td>55.057598</td>\n",
       "      <td>145.079620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.185539</td>\n",
       "      <td>1189.010010</td>\n",
       "      <td>93.336891</td>\n",
       "      <td>282.886353</td>\n",
       "      <td>27.561298</td>\n",
       "      <td>...</td>\n",
       "      <td>1442900.0</td>\n",
       "      <td>32195600.0</td>\n",
       "      <td>2285200.0</td>\n",
       "      <td>8509000.0</td>\n",
       "      <td>5215419.0</td>\n",
       "      <td>4236200.0</td>\n",
       "      <td>3485000.0</td>\n",
       "      <td>4298000.0</td>\n",
       "      <td>5413000.0</td>\n",
       "      <td>5367700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>41.180996</td>\n",
       "      <td>82.328041</td>\n",
       "      <td>55.179340</td>\n",
       "      <td>145.749237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.775501</td>\n",
       "      <td>1204.199951</td>\n",
       "      <td>93.912346</td>\n",
       "      <td>283.801270</td>\n",
       "      <td>27.469122</td>\n",
       "      <td>...</td>\n",
       "      <td>1849300.0</td>\n",
       "      <td>39162500.0</td>\n",
       "      <td>4851700.0</td>\n",
       "      <td>6057500.0</td>\n",
       "      <td>4033141.0</td>\n",
       "      <td>6918900.0</td>\n",
       "      <td>2417600.0</td>\n",
       "      <td>4653700.0</td>\n",
       "      <td>5655600.0</td>\n",
       "      <td>5043800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>41.372276</td>\n",
       "      <td>81.858551</td>\n",
       "      <td>55.085686</td>\n",
       "      <td>147.475006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.990028</td>\n",
       "      <td>1209.589966</td>\n",
       "      <td>95.474388</td>\n",
       "      <td>282.724426</td>\n",
       "      <td>27.828621</td>\n",
       "      <td>...</td>\n",
       "      <td>2159500.0</td>\n",
       "      <td>27865700.0</td>\n",
       "      <td>2878800.0</td>\n",
       "      <td>7124500.0</td>\n",
       "      <td>3544977.0</td>\n",
       "      <td>5460400.0</td>\n",
       "      <td>2749100.0</td>\n",
       "      <td>4384900.0</td>\n",
       "      <td>5473100.0</td>\n",
       "      <td>7583600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>41.843315</td>\n",
       "      <td>83.283516</td>\n",
       "      <td>55.244900</td>\n",
       "      <td>148.691528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.213501</td>\n",
       "      <td>1229.140015</td>\n",
       "      <td>95.692131</td>\n",
       "      <td>294.322296</td>\n",
       "      <td>27.957666</td>\n",
       "      <td>...</td>\n",
       "      <td>2126500.0</td>\n",
       "      <td>22194900.0</td>\n",
       "      <td>3203100.0</td>\n",
       "      <td>5549700.0</td>\n",
       "      <td>5438495.0</td>\n",
       "      <td>5254900.0</td>\n",
       "      <td>2432800.0</td>\n",
       "      <td>5381200.0</td>\n",
       "      <td>3699200.0</td>\n",
       "      <td>6863200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>41.687897</td>\n",
       "      <td>81.949142</td>\n",
       "      <td>55.085686</td>\n",
       "      <td>149.879791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.855946</td>\n",
       "      <td>1246.869995</td>\n",
       "      <td>94.811699</td>\n",
       "      <td>295.570709</td>\n",
       "      <td>27.764093</td>\n",
       "      <td>...</td>\n",
       "      <td>1874900.0</td>\n",
       "      <td>26643900.0</td>\n",
       "      <td>3887200.0</td>\n",
       "      <td>8337200.0</td>\n",
       "      <td>11114059.0</td>\n",
       "      <td>4549400.0</td>\n",
       "      <td>2850800.0</td>\n",
       "      <td>5472300.0</td>\n",
       "      <td>3243000.0</td>\n",
       "      <td>6817400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>148.423386</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>126.580002</td>\n",
       "      <td>356.440002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.639999</td>\n",
       "      <td>3320.370117</td>\n",
       "      <td>182.309998</td>\n",
       "      <td>212.869995</td>\n",
       "      <td>47.509998</td>\n",
       "      <td>...</td>\n",
       "      <td>1537200.0</td>\n",
       "      <td>49626100.0</td>\n",
       "      <td>6563500.0</td>\n",
       "      <td>2488400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4254900.0</td>\n",
       "      <td>3553500.0</td>\n",
       "      <td>3158000.0</td>\n",
       "      <td>4829700.0</td>\n",
       "      <td>3043600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>149.102402</td>\n",
       "      <td>109.489998</td>\n",
       "      <td>128.130005</td>\n",
       "      <td>356.339996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.230000</td>\n",
       "      <td>3376.070068</td>\n",
       "      <td>180.949997</td>\n",
       "      <td>209.809998</td>\n",
       "      <td>47.959999</td>\n",
       "      <td>...</td>\n",
       "      <td>1973700.0</td>\n",
       "      <td>36395600.0</td>\n",
       "      <td>2341600.0</td>\n",
       "      <td>2439700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5837500.0</td>\n",
       "      <td>3103900.0</td>\n",
       "      <td>2409700.0</td>\n",
       "      <td>6596500.0</td>\n",
       "      <td>3825600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>148.633087</td>\n",
       "      <td>108.400002</td>\n",
       "      <td>127.709999</td>\n",
       "      <td>354.049988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.549999</td>\n",
       "      <td>3392.489990</td>\n",
       "      <td>178.029999</td>\n",
       "      <td>206.610001</td>\n",
       "      <td>47.040001</td>\n",
       "      <td>...</td>\n",
       "      <td>1178000.0</td>\n",
       "      <td>39994000.0</td>\n",
       "      <td>3879200.0</td>\n",
       "      <td>2269700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10365500.0</td>\n",
       "      <td>3520400.0</td>\n",
       "      <td>2886300.0</td>\n",
       "      <td>3309000.0</td>\n",
       "      <td>7255000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>152.347656</td>\n",
       "      <td>109.669998</td>\n",
       "      <td>127.709999</td>\n",
       "      <td>356.320007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.900002</td>\n",
       "      <td>3446.570068</td>\n",
       "      <td>174.610001</td>\n",
       "      <td>207.850006</td>\n",
       "      <td>47.779999</td>\n",
       "      <td>...</td>\n",
       "      <td>1627900.0</td>\n",
       "      <td>53082600.0</td>\n",
       "      <td>2574900.0</td>\n",
       "      <td>1735200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5123000.0</td>\n",
       "      <td>1672600.0</td>\n",
       "      <td>1998200.0</td>\n",
       "      <td>2236400.0</td>\n",
       "      <td>3979100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-29</th>\n",
       "      <td>149.581696</td>\n",
       "      <td>114.669998</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>358.790009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.090000</td>\n",
       "      <td>3372.429932</td>\n",
       "      <td>173.779999</td>\n",
       "      <td>207.029999</td>\n",
       "      <td>47.779999</td>\n",
       "      <td>...</td>\n",
       "      <td>2777200.0</td>\n",
       "      <td>54157900.0</td>\n",
       "      <td>8402700.0</td>\n",
       "      <td>2417400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4552200.0</td>\n",
       "      <td>2496700.0</td>\n",
       "      <td>2387000.0</td>\n",
       "      <td>2362000.0</td>\n",
       "      <td>4008400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>981 rows × 372 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close                                                     \\\n",
       "                  AAPL        ABBV         ABT         ACN AGN        AIG   \n",
       "Date                                                                        \n",
       "2018-01-02   41.188160   81.059563   55.057598  145.079620 NaN  53.185539   \n",
       "2018-01-03   41.180996   82.328041   55.179340  145.749237 NaN  53.775501   \n",
       "2018-01-04   41.372276   81.858551   55.085686  147.475006 NaN  53.990028   \n",
       "2018-01-05   41.843315   83.283516   55.244900  148.691528 NaN  54.213501   \n",
       "2018-01-08   41.687897   81.949142   55.085686  149.879791 NaN  53.855946   \n",
       "...                ...         ...         ...         ...  ..        ...   \n",
       "2021-10-25  148.423386  108.500000  126.580002  356.440002 NaN  59.639999   \n",
       "2021-10-26  149.102402  109.489998  128.130005  356.339996 NaN  59.230000   \n",
       "2021-10-27  148.633087  108.400002  127.709999  354.049988 NaN  58.549999   \n",
       "2021-10-28  152.347656  109.669998  127.709999  356.320007 NaN  59.900002   \n",
       "2021-10-29  149.581696  114.669998  128.889999  358.790009 NaN  59.090000   \n",
       "\n",
       "                                                            ...     Volume  \\\n",
       "                   AMZN         AXP          BA        BAC  ...        SPG   \n",
       "Date                                                        ...              \n",
       "2018-01-02  1189.010010   93.336891  282.886353  27.561298  ...  1442900.0   \n",
       "2018-01-03  1204.199951   93.912346  283.801270  27.469122  ...  1849300.0   \n",
       "2018-01-04  1209.589966   95.474388  282.724426  27.828621  ...  2159500.0   \n",
       "2018-01-05  1229.140015   95.692131  294.322296  27.957666  ...  2126500.0   \n",
       "2018-01-08  1246.869995   94.811699  295.570709  27.764093  ...  1874900.0   \n",
       "...                 ...         ...         ...        ...  ...        ...   \n",
       "2021-10-25  3320.370117  182.309998  212.869995  47.509998  ...  1537200.0   \n",
       "2021-10-26  3376.070068  180.949997  209.809998  47.959999  ...  1973700.0   \n",
       "2021-10-27  3392.489990  178.029999  206.610001  47.040001  ...  1178000.0   \n",
       "2021-10-28  3446.570068  174.610001  207.850006  47.779999  ...  1627900.0   \n",
       "2021-10-29  3372.429932  173.779999  207.029999  47.779999  ...  2777200.0   \n",
       "\n",
       "                                                                      \\\n",
       "                     T      TD.TO        TGT         TWX         TXN   \n",
       "Date                                                                   \n",
       "2018-01-02  32195600.0  2285200.0  8509000.0   5215419.0   4236200.0   \n",
       "2018-01-03  39162500.0  4851700.0  6057500.0   4033141.0   6918900.0   \n",
       "2018-01-04  27865700.0  2878800.0  7124500.0   3544977.0   5460400.0   \n",
       "2018-01-05  22194900.0  3203100.0  5549700.0   5438495.0   5254900.0   \n",
       "2018-01-08  26643900.0  3887200.0  8337200.0  11114059.0   4549400.0   \n",
       "...                ...        ...        ...         ...         ...   \n",
       "2021-10-25  49626100.0  6563500.0  2488400.0         NaN   4254900.0   \n",
       "2021-10-26  36395600.0  2341600.0  2439700.0         NaN   5837500.0   \n",
       "2021-10-27  39994000.0  3879200.0  2269700.0         NaN  10365500.0   \n",
       "2021-10-28  53082600.0  2574900.0  1735200.0         NaN   5123000.0   \n",
       "2021-10-29  54157900.0  8402700.0  2417400.0         NaN   4552200.0   \n",
       "\n",
       "                                                        \n",
       "                  UNH        UNP        UPS        USB  \n",
       "Date                                                    \n",
       "2018-01-02  3485000.0  4298000.0  5413000.0  5367700.0  \n",
       "2018-01-03  2417600.0  4653700.0  5655600.0  5043800.0  \n",
       "2018-01-04  2749100.0  4384900.0  5473100.0  7583600.0  \n",
       "2018-01-05  2432800.0  5381200.0  3699200.0  6863200.0  \n",
       "2018-01-08  2850800.0  5472300.0  3243000.0  6817400.0  \n",
       "...               ...        ...        ...        ...  \n",
       "2021-10-25  3553500.0  3158000.0  4829700.0  3043600.0  \n",
       "2021-10-26  3103900.0  2409700.0  6596500.0  3825600.0  \n",
       "2021-10-27  3520400.0  2886300.0  3309000.0  7255000.0  \n",
       "2021-10-28  1672600.0  1998200.0  2236400.0  3979100.0  \n",
       "2021-10-29  2496700.0  2387000.0  2362000.0  4008400.0  \n",
       "\n",
       "[981 rows x 372 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Financial Data\n",
    "\n",
    "unfiltered_tickers = results\n",
    "\n",
    "start_date = \"2018-01-02\"\n",
    "end_date = \"2021-10-31\"\n",
    "\n",
    "data = yf.download(unfiltered_tickers, start=start_date, end=end_date)\n",
    "\n",
    "data\n",
    "\n",
    "# =============================================\n",
    "# # Filters out invalid stocks\n",
    "# list_of_tickers = filter_tickers(no_nan)\n",
    "\n",
    "# updated_data = yf.download(list_of_tickers, start=start_date, end=end_date)\n",
    "\n",
    "# This list of valid tickers will be used later when generating the portfolio\n",
    "\n",
    "#==================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n",
      "USD\n"
     ]
    }
   ],
   "source": [
    "# Get Closing Prices and Volume Data\n",
    "closing_data = data['Adj Close']\n",
    "volume_data = data['Volume']\n",
    "\n",
    "# Filter based on Volume\n",
    "volume = volume_data.loc[\"2021-07-02\":\"2021-10-22\"].mean().dropna()\n",
    "\n",
    "volume2 = pd.DataFrame(volume, columns=['Volume'])\n",
    "\n",
    "volume_valid = list(volume2[volume2.Volume > 10000].index)\n",
    "\n",
    "closing_data = closing_data[volume_valid]\n",
    "\n",
    "# Filter based on NaN values\n",
    "\n",
    "no_nan_tickers = filters_nan(closing_data)\n",
    "\n",
    "no_nan = closing_data[no_nan_tickers]\n",
    "\n",
    "no_nan\n",
    "\n",
    "# Filter based on currency\n",
    "\n",
    "for i in range(len(no_nan_tickers)):\n",
    "    ticker = yf.Ticker(no_nan_tickers[i])\n",
    "    print(ticker.info['currency'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare price fluctuations, we will calculate the daily percentage change in the price of each stock. By calculating percent change, it makes it easier to compare price fluctuations between stocks as the magnitude of the price changes will be compared, removing the influence of the share price from the price fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate percent change\n",
    "\n",
    "percent_change = closing_prices.pct_change().apply(lambda x: np.log(1+x))\n",
    "\n",
    "percent_change.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Efficient Frontier Graph\n",
    "To construct an Efficient Frontier Graph, we require three factors:\n",
    "- Covariance of the securities in the portfolio\n",
    "- Standard deviation also known as risk\n",
    "- The expected return of the portfolio\n",
    "\n",
    "Below, we will be calculating all these three factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance\n",
    "\n",
    "We will now analyze the covariance of each stock in relation to one another. The covariance of two stocks (stock X, stock Y) is calculated using the following equation:\n",
    "\n",
    "\\begin{align*}\n",
    "COV(X,Y)=\\frac{\\sum(x_i-\\overline{X})\\times(y_i-\\overline{Y})}{N}\n",
    "\\end{align*}\n",
    "\n",
    "We will store the results of the covariance calculations in 'cov_matrix'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = percent_change.cov()\n",
    "\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Deviation\n",
    "\n",
    "To calculate standard deviation, we need to calculate the correlation between stocks.\n",
    "\n",
    "To do this, we will use a correlation matrix.\n",
    "\n",
    "The correlation of two stocks (stock X, stock Y) is calculated using the following equation:\n",
    "\n",
    "\\begin{align*}\n",
    "\\rho(X,Y)=\\frac{COV(X,Y)}{\\sigma_X \\sigma_Y}\n",
    "\\end{align*}\n",
    "\n",
    "Where $\\rho_{x,y}$ is the correlation between the two variables, $cov(r_x, r_y)$ is the covariance of return X and return Y, and $\\sigma_x$ and $\\sigma_y$ are the standard deviations of X and Y respectively.\n",
    "\n",
    "Note that each stock has a correlation of 1 with itself, a perfect positive correlation.\n",
    "\n",
    "There exists a positive correlation between stocks X and Y if $0 < \\rho_{x,y} < 1$.\n",
    "\n",
    "There exists a negative (inverse) correlation between stocks X and Y if $-1 < \\rho_{x,y} < 0$.\n",
    "\n",
    "There exists no (zero) correlation between stocks X and Y if $\\rho_{x,y} = 0$. In reality, it is almost impossible for two stocks to have zero correlation with each other.\n",
    "\n",
    "We will store the results of the correlation calculations in 'corr_matrix'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = percent_change.corr()\n",
    "\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Return\n",
    "Finally, we will calculate the expected return of each portfolio. The expected return of a portfolio is caluclated by the equation below:\n",
    "\n",
    "\\begin{align*}\n",
    "E(X)=\\overline{X}=\\frac{\\sum x_i}{N}\n",
    "\\end{align*}\n",
    "\n",
    "where $x_i$ are individual returns of some security $X$, $N$ is the total number of observations (time periods for us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate Yearly Expected Returns (Returns)\n",
    "\n",
    "individual_expected_returns = closing_prices.resample('Y').first().pct_change().mean()\n",
    "\n",
    "yearly_stats = pd.DataFrame(individual_expected_returns, columns=['Returns'])\n",
    "\n",
    "# Calculate Annual Standard Deviation (Volatility)\n",
    "\n",
    "trading_days = 250\n",
    "\n",
    "annual_standard_deviation = percent_change.std().apply(lambda x: x * np.sqrt(trading_days))\n",
    "\n",
    "yearly_stats['Volatility'] = annual_standard_deviation\n",
    "\n",
    "yearly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this number to change the number of randomly generated portfolios\n",
    "# The more number of random portfolios generated, the more optimized\n",
    "#   the final optimized portfolio will be\n",
    "\n",
    "number_of_portfolios = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate portfolios with random weights\n",
    "\n",
    "# generate_portfolios(tickers, number_of_portfolios) generates\n",
    "#   a collection of [number_of_portfolios] portfolios from the\n",
    "#   list of [tickers]\n",
    "\n",
    "\"\"\"\n",
    "Params:\n",
    "    tickers (listof Str): List of stock tickers to choose from\n",
    "    number_of_portfolios (Nat): Number of portfolios to generate\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_portfolios(tickers, number_of_portfolios):\n",
    "    weights = []\n",
    "    returns = []\n",
    "    volatility = []\n",
    "\n",
    "    for i in range(number_of_portfolios):\n",
    "        individual_weights = np.random.random(len(tickers))\n",
    "        individual_weights = individual_weights / np.sum(individual_weights)\n",
    "        weights.append(individual_weights)\n",
    "\n",
    "        individual_returns = np.dot(individual_weights, yearly_stats.Returns)\n",
    "        returns.append(individual_returns)\n",
    "\n",
    "        portfolio_variance = (\n",
    "            cov_matrix.mul(individual_weights, axis=0)\n",
    "            .mul(individual_weights, axis=1)\n",
    "            .sum()\n",
    "            .sum()\n",
    "        )\n",
    "        standard_deviation = np.sqrt(portfolio_variance)\n",
    "        individual_volatility = standard_deviation * np.sqrt(trading_days)\n",
    "        volatility.append(individual_volatility)\n",
    "\n",
    "    portfolios = pd.DataFrame(index=range(number_of_portfolios))\n",
    "\n",
    "    portfolios[\"Returns\"] = returns\n",
    "    portfolios[\"Volatility\"] = volatility\n",
    "\n",
    "    for i in range(len(tickers)):\n",
    "        for j in range(number_of_portfolios):\n",
    "            portfolios[tickers[i]] = weights[j][i]\n",
    "\n",
    "    return portfolios\n",
    "\n",
    "\n",
    "random_portfolios = generate_portfolios(tickers, number_of_portfolios)\n",
    "\n",
    "random_portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick optimal portfolio\n",
    "\n",
    "safest_portfolio = random_portfolios.iloc[random_portfolios.Volatility.idxmin()]\n",
    "\n",
    "pd.DataFrame(safest_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Efficient Frontier Graph\n",
    "\n",
    "plt.subplots(figsize=[10, 10])\n",
    "\n",
    "plt.scatter(x=random_portfolios.Volatility, y=random_portfolios.Returns, s=10, alpha=0.7)\n",
    "\n",
    "plt.scatter(safest_portfolio.Volatility, safest_portfolio.Returns, color='r', marker='*', s=200)\n",
    "\n",
    "plt.title(\"Efficient Frontier of Randomly Generated Portfolios\")\n",
    "plt.xlabel(\"Volatility\")\n",
    "plt.ylabel(\"Returns\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebalance optimal portfolio to top 20 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rebalanced portfolio onto Efficient Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce final list of chosen tickers and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Derek, Yuqian, Jeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "Image Link: https://www.cryptimi.com/guides/is-diversification-the-right-strategy-for-your-cryptocurrency-portfolio\n",
    "\n",
    "Equations: Professor Thompson's notes\n",
    "\n",
    "\n",
    "Definition of MPT & EF: https://www.investopedia.com/terms/e/efficientfrontier.asp https://www.investopedia.com/terms/m/modernportfoliotheory.asp\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e28298bb47a08697a860182f4406c1126f813946b24568f02bad9bcf7ea902f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
