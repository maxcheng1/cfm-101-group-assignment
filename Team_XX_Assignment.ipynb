{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Assignment\n",
    "### Team Number: 3\n",
    "### Team Member Names: Derek Tan, Jeff Peng, Yuqian Lin\n",
    "### Team Strategy Chosen: SAFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "Our portfolio optimization strategy involves the use and implementation of the Modern Portfolio Theory (MPT) and analysis of the Efficient Frontier graphs. The objective of the portfolio optimization strategy is to maximize the portfolio return while maintaining the minimum portfolio risk. \n",
    "\n",
    "Modern Portfolio Theory states that since it is assumed that all investors are risk-adverse, when considering the possible portfolio allocation strategies, the investor will prefer the portfolio that maximizes the possible return while maintaining a given amount of risk. \n",
    "\n",
    "The Efficient Frontier (EF), the core of our strategy, was introduced by Nobel Laureate Harry Markowitz and is fundamental to MPT. The EP is a graph that illustrates all possible portfolios portfolio allocation distributions. The x-axis represents the volatility/risk of the portfolio, while the y-axis represents the expected return of the portfolio.\n",
    "\n",
    "The Efficient Frontier shows the optimized portfolios that offer the highest expected return for a given level of risk and the lowest level of risk for a given level of expected return.\n",
    "\n",
    "An example of the an Efficient Frontier graph is shown below:\n",
    "\n",
    "![EF Graph](ef.png)\n",
    "\n",
    "As seen from the graph, the light blue dot is the portfolio that takes on the highest level of risk coupled with the highest degree of return. Conversely, the left-most purple dot depicts the portfolio that with the lowest level of risk and lowest given level of return. Typically, risk-seeking investors will select portfolios that lie on the right end as they yield a higher return for a high level of risk. In our group's case, we chose the \"safe\" strategy, and thus will be selecting the portfolio on the left-end of the graph as it yields a lower return for a lower level of risk.\n",
    "\n",
    "We will be discussing more about how we graphed each portfolio along the EF graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing our strategy, we have to filter out any invalid stock tickers. That is, any tickers that are not traded in USD and tickers with an average daily volume of less than 10000 shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "results = []\n",
    "with open('Tickers.csv', newline='') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        results.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter list of tickers for valid tickers\n",
    "\n",
    "# filter_tickers(list_of_tickers) produces a list of tickers\n",
    "#   of all tickers in [list_of_tickers] that have a daily \n",
    "#   average volume above 10 000 shares and are traded in USD\n",
    "\n",
    "\"\"\"\n",
    "Params:\n",
    "    list_of_tickers (listof Str): Unfiltered original list of tickers\n",
    "\"\"\"\n",
    "\n",
    "def filter_tickers(list_of_tickers):\n",
    "    valid_tickers = []\n",
    "    \n",
    "    start_date = \"2021-07-02\"\n",
    "    end_date = \"2021-10-22\"\n",
    "\n",
    "    for i in range(len(list_of_tickers)):\n",
    "        ticker = yf.Ticker(list_of_tickers[i])\n",
    "        ticker_hist = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "        if ticker_hist[\"Volume\"].mean() >= 10000 or ticker.info[\"currency\"] == \"USD\":\n",
    "            valid_tickers.append(list_of_tickers[i])\n",
    "\n",
    "    return valid_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters_nan(ticker_list) filters out stocks with invalid prices, that is stocks with NaN values.\n",
    "#It then produces a list of these filtered tickers\n",
    "\n",
    "\"\"\"\n",
    "Params:\n",
    "    ticker_list (listof Str): Unfiltered original list of tickers\n",
    "\"\"\"\n",
    "\n",
    "def filters_nan(ticker_list):\n",
    "    start_date = \"2018-01-02\"\n",
    "    end_date = \"2021-10-31\"\n",
    "    no_nan = []\n",
    "    \n",
    "    for i in range (ticker_list.shape[1]):\n",
    "        if ticker_list.iloc[:, i].isna().sum() == 0:\n",
    "            no_nan.append((ticker_list.columns)[i])\n",
    "        \n",
    "    return no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  62 of 62 completed\n",
      "\n",
      "4 Failed downloads:\n",
      "- PCLN: No data found for this date range, symbol may be delisted\n",
      "- AGN: No data found, symbol may be delisted\n",
      "- CELG: No data found, symbol may be delisted\n",
      "- RTN: No data found, symbol may be delisted\n",
      "- AGN: No data found, symbol may be delisted\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'currency'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-27d6b6b2f111>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Filters out invalid stocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mlist_of_tickers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_tickers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munfiltered_CP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mupdated_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_tickers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-b9e4aba66c4c>\u001b[0m in \u001b[0;36mfilter_tickers\u001b[1;34m(list_of_tickers)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mticker_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mticker_hist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Volume\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"currency\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"USD\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mvalid_tickers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_tickers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'currency'"
     ]
    }
   ],
   "source": [
    "# Import Financial Data\n",
    "\n",
    "unfiltered_tickers = results\n",
    "\n",
    "start_date = \"2018-01-02\"\n",
    "end_date = \"2021-10-31\"\n",
    "\n",
    "\n",
    "# Testing on S&P 500 Tickers\n",
    "# wiki_page = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "\n",
    "# Removed BF.B and BRK.B since they are delisted and obsolete\n",
    "# unfiltered_tickers = wiki_page[0].Symbol.values.tolist()\n",
    "\n",
    "# Testing on Sample File\n",
    "# unfiltered_tickers = [\"CSCO\", \"TGT\", \"BK\", \"MRK\", \"PFE\", \"COP\", \"LLY\", \"CL\", \"GOOG\", \"COF\"]\n",
    "data = yf.download(unfiltered_tickers[0:100], start=start_date, end=end_date)\n",
    "unfiltered_CP = data[\"Adj Close\"]\n",
    "\n",
    "# Filter out stocks with NaN values\n",
    "# no_nan = filters_nan(unfiltered_CP)\n",
    "\n",
    "# Filters out invalid stocks\n",
    "list_of_tickers = filter_tickers(unfiltered_CP.columns)\n",
    "\n",
    "updated_data = yf.download(list_of_tickers, start=start_date, end=end_date)\n",
    "closing_prices = updated_data[\"Adj Close\"]\n",
    "\n",
    "# This list of valid tickers will be used later when generating the portfolio\n",
    "tickers = closing_prices.columns\n",
    "\n",
    "# Note: Please give it some time to run. It shouldn't take too long, but you should be seeing 2 separate downloads. If not,\n",
    "# please wait a for a while."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare price fluctuations, we will calculate the daily percentage change in the price of each stock. By calculating percent change, it makes it easier to compare price fluctuations between stocks as the magnitude of the price changes will be compared, removing the influence of the share price from the price fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate percent change\n",
    "\n",
    "percent_change = closing_prices.pct_change().apply(lambda x: np.log(1+x))\n",
    "\n",
    "percent_change.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Efficient Frontier Graph\n",
    "To construct an Efficient Frontier Graph, we require three factors:\n",
    "- Covariance of the securities in the portfolio\n",
    "- Standard deviation also known as risk\n",
    "- The expected return of the portfolio\n",
    "\n",
    "Below, we will be calculating all these three factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance\n",
    "\n",
    "We will now analyze the covariance of each stock in relation to one another. The covariance of two stocks (stock X, stock Y) is calculated using the following equation:\n",
    "\n",
    "\\begin{align*}\n",
    "COV(X,Y)=\\frac{\\sum(x_i-\\overline{X})\\times(y_i-\\overline{Y})}{N}\n",
    "\\end{align*}\n",
    "\n",
    "We will store the results of the covariance calculations in 'cov_matrix'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = percent_change.cov()\n",
    "\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Deviation\n",
    "\n",
    "To calculate standard deviation, we need to calculate the correlation between stocks.\n",
    "\n",
    "To do this, we will use a correlation matrix.\n",
    "\n",
    "The correlation of two stocks (stock X, stock Y) is calculated using the following equation:\n",
    "\n",
    "\\begin{align*}\n",
    "\\rho(X,Y)=\\frac{COV(X,Y)}{\\sigma_X \\sigma_Y}\n",
    "\\end{align*}\n",
    "\n",
    "Where $\\rho_{x,y}$ is the correlation between the two variables, $cov(r_x, r_y)$ is the covariance of return X and return Y, and $\\sigma_x$ and $\\sigma_y$ are the standard deviations of X and Y respectively.\n",
    "\n",
    "Note that each stock has a correlation of 1 with itself, a perfect positive correlation.\n",
    "\n",
    "There exists a positive correlation between stocks X and Y if $0 < \\rho_{x,y} < 1$.\n",
    "\n",
    "There exists a negative (inverse) correlation between stocks X and Y if $-1 < \\rho_{x,y} < 0$.\n",
    "\n",
    "There exists no (zero) correlation between stocks X and Y if $\\rho_{x,y} = 0$. In reality, it is almost impossible for two stocks to have zero correlation with each other.\n",
    "\n",
    "We will store the results of the correlation calculations in 'corr_matrix'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = percent_change.corr()\n",
    "\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Return\n",
    "Finally, we will calculate the expected return of each portfolio. The expected return of a portfolio is caluclated by the equation below:\n",
    "\n",
    "\\begin{align*}\n",
    "E(X)=\\overline{X}=\\frac{\\sum x_i}{N}\n",
    "\\end{align*}\n",
    "\n",
    "where $x_i$ are individual returns of some security $X$, $N$ is the total number of observations (time periods for us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_prices.resample('Y').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate Yearly Expected Returns (Returns)\n",
    "\n",
    "individual_expected_returns = closing_prices.resample('Y').first().pct_change().mean()\n",
    "\n",
    "yearly_stats = pd.DataFrame(individual_expected_returns, columns=['Returns'])\n",
    "\n",
    "# Calculate Annual Standard Deviation (Volatility)\n",
    "\n",
    "trading_days = 250\n",
    "\n",
    "annual_standard_deviation = percent_change.std().apply(lambda x: x * np.sqrt(trading_days))\n",
    "\n",
    "yearly_stats['Volatility'] = annual_standard_deviation\n",
    "\n",
    "yearly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this number to change the number of randomly generated portfolios\n",
    "# The more number of random portfolios generated, the more optimized\n",
    "#   the final optimized portfolio will be\n",
    "\n",
    "number_of_portfolios = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate portfolios with random weights\n",
    "\n",
    "# generate_portfolios(tickers, number_of_portfolios) generates\n",
    "#   a collection of [number_of_portfolios] portfolios from the\n",
    "#   list of [tickers]\n",
    "\n",
    "\"\"\"\n",
    "Params:\n",
    "    tickers (listof Str): List of stock tickers to choose from\n",
    "    number_of_portfolios (Nat): Number of portfolios to generate\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_portfolios(tickers, number_of_portfolios):\n",
    "    weights = []\n",
    "    returns = []\n",
    "    volatility = []\n",
    "\n",
    "    for i in range(number_of_portfolios):\n",
    "        individual_weights = np.random.random(len(tickers))\n",
    "        individual_weights = individual_weights / np.sum(individual_weights)\n",
    "        weights.append(individual_weights)\n",
    "\n",
    "        individual_returns = np.dot(individual_weights, yearly_stats.Returns)\n",
    "        returns.append(individual_returns)\n",
    "\n",
    "        portfolio_variance = (\n",
    "            cov_matrix.mul(individual_weights, axis=0)\n",
    "            .mul(individual_weights, axis=1)\n",
    "            .sum()\n",
    "            .sum()\n",
    "        )\n",
    "        standard_deviation = np.sqrt(portfolio_variance)\n",
    "        individual_volatility = standard_deviation * np.sqrt(trading_days)\n",
    "        volatility.append(individual_volatility)\n",
    "\n",
    "    portfolios = pd.DataFrame(index=range(number_of_portfolios))\n",
    "\n",
    "    portfolios[\"Returns\"] = returns\n",
    "    portfolios[\"Volatility\"] = volatility\n",
    "\n",
    "    for i in range(len(tickers)):\n",
    "        for j in range(number_of_portfolios):\n",
    "            portfolios[tickers[i]] = weights[j][i]\n",
    "\n",
    "    return portfolios\n",
    "\n",
    "\n",
    "random_portfolios = generate_portfolios(tickers, number_of_portfolios)\n",
    "\n",
    "random_portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick optimal portfolio\n",
    "\n",
    "safest_portfolio = random_portfolios.iloc[random_portfolios.Volatility.idxmin()]\n",
    "\n",
    "pd.DataFrame(safest_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Efficient Frontier Graph\n",
    "\n",
    "plt.subplots(figsize=[10, 10])\n",
    "\n",
    "plt.scatter(x=random_portfolios.Volatility, y=random_portfolios.Returns, s=10, alpha=0.7)\n",
    "\n",
    "plt.scatter(safest_portfolio.Volatility, safest_portfolio.Returns, color='r', marker='*', s=200)\n",
    "\n",
    "plt.title(\"Efficient Frontier of Randomly Generated Portfolios\")\n",
    "plt.xlabel(\"Volatility\")\n",
    "plt.ylabel(\"Returns\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebalance optimal portfolio to top 20 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rebalanced portfolio onto Efficient Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce final list of chosen tickers and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Derek, Yuqian, Jeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "Image Link: https://www.cryptimi.com/guides/is-diversification-the-right-strategy-for-your-cryptocurrency-portfolio\n",
    "\n",
    "Equations: Professor Thompson's notes\n",
    "\n",
    "\n",
    "Definition of MPT & EF: https://www.investopedia.com/terms/e/efficientfrontier.asp https://www.investopedia.com/terms/m/modernportfoliotheory.asp\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e28298bb47a08697a860182f4406c1126f813946b24568f02bad9bcf7ea902f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
