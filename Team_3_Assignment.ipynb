{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Assignment\n",
    "### Team Number: 3\n",
    "### Team Member Names: Derek Tan, Jeff Peng, Yuqian Lin\n",
    "### Team Strategy Chosen: SAFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "Our portfolio optimization strategy involves the use and implementation of the Modern Portfolio Theory (MPT) and analysis of the Efficient Frontier graphs. The objective of the portfolio optimization strategy is to maximize the portfolio return while maintaining the minimum portfolio risk. \n",
    "\n",
    "Modern Portfolio Theory states that since it is assumed that all investors are risk-adverse, when considering the possible portfolio allocation strategies, the investor will prefer the portfolio that maximizes the possible return while maintaining a given amount of risk. \n",
    "\n",
    "The Efficient Frontier (EF), the core of our strategy, was introduced by Nobel Laureate Harry Markowitz and is fundamental to MPT. The EF is a graph that illustrates all possible portfolios portfolio allocation distributions. The x-axis represents the volatility/risk of the portfolio, while the y-axis represents the expected return of the portfolio.\n",
    "\n",
    "The Efficient Frontier shows the optimized portfolios that offer the highest expected return for a given level of risk and the lowest level of risk for a given level of expected return.\n",
    "\n",
    "An example of the an Efficient Frontier graph is shown below:\n",
    "\n",
    "![EF Graph](ef.png)\n",
    "\n",
    "As seen from the graph, the light blue dot is the portfolio that takes on the highest level of risk coupled with the highest degree of return. Conversely, the left-most purple dot depicts the portfolio that with the lowest level of risk and lowest given level of return. Typically, risk-seeking investors will select portfolios that lie on the right end as they yield a higher return for a high level of risk. In our group's case, we chose the \"safe\" strategy, and thus will be selecting the portfolio on the left-end of the graph as it yields a lower return for a lower level of risk.\n",
    "\n",
    "Note: We will be discussing more about how we graphed each portfolio along the EF graph below. Additionally, we will also provide a comprehensive conclusion of our strategy and analysis at the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports CSV file's tickers a list\n",
    "ticker_df = pd.read_csv(\"Tickers.csv\", index_col=False)\n",
    "results = list(ticker_df.iloc[:, 0])\n",
    "results.insert(0, ticker_df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters_nan(ticker_list) filters out stocks with invalid prices, that is stocks with NaN values.\n",
    "# It then produces a list of these filtered tickers\n",
    "\n",
    "\"\"\"\n",
    "Params:\n",
    "    ticker_list (listof Str): Unfiltered original list of tickers\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def filters_nan(ticker_list):\n",
    "    start_date = \"2018-01-02\"\n",
    "    end_date = \"2021-10-31\"\n",
    "    no_nan = []\n",
    "\n",
    "    for i in range(ticker_list.shape[1]):\n",
    "        if ticker_list.iloc[:, i].isna().sum() < len(ticker_list) - 209:\n",
    "            no_nan.append((ticker_list.columns)[i])\n",
    "\n",
    "    return no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Financial Data\n",
    "\n",
    "unfiltered_tickers = results\n",
    "\n",
    "start_date = \"2018-01-02\"\n",
    "end_date = \"2021-10-31\"\n",
    "\n",
    "data = yf.download(unfiltered_tickers, start=start_date, end=end_date)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Closing Prices and Volume Data\n",
    "closing_data = data[\"Adj Close\"]\n",
    "volume_data = data[\"Volume\"]\n",
    "\n",
    "volume_start_date = datetime.strptime(\"2021-07-02\", \"%Y-%m-%d\")\n",
    "volume_end_date = datetime.strptime(\"2021-10-22\", \"%Y-%m-%d\")\n",
    "\n",
    "# Filter based on Volume\n",
    "volume = volume_data.loc[volume_start_date:volume_end_date].mean().dropna()\n",
    "\n",
    "volume2 = pd.DataFrame(volume, columns=[\"Volume\"])\n",
    "\n",
    "volume_valid = list(volume2[volume2.Volume > 10000].index)\n",
    "\n",
    "closing_data = closing_data[volume_valid]\n",
    "\n",
    "# Filter based on NaN values\n",
    "\n",
    "no_nan_tickers = filters_nan(closing_data)\n",
    "\n",
    "no_nan = closing_data[no_nan_tickers]\n",
    "\n",
    "# Filter based on currency\n",
    "\n",
    "valid_tickers = []\n",
    "\n",
    "for i in range(len(no_nan_tickers)):\n",
    "    info = yf.Ticker(no_nan_tickers[i]).info\n",
    "    div = info.get(\"currency\")\n",
    "    if div == \"USD\":\n",
    "        valid_tickers.append(no_nan_tickers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_prices = closing_data[valid_tickers]\n",
    "\n",
    "closing_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare price fluctuations, we will calculate the daily percentage change in the price of each stock. By calculating percent change, it makes it easier to compare price fluctuations between stocks as the magnitude of the price changes will be compared, removing the influence of the share price from the price fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate percent change\n",
    "\n",
    "percent_change = closing_prices.pct_change().apply(lambda x: np.log(1 + x))\n",
    "\n",
    "percent_change.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Efficient Frontier Graph\n",
    "To construct an Efficient Frontier Graph, we require three factors:\n",
    "- Covariance of the securities in the portfolio\n",
    "- Standard deviation also known as risk\n",
    "- The expected return of the portfolio\n",
    "\n",
    "Below, we will be calculating all these three factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance\n",
    "\n",
    "We will now analyze the covariance of each stock in relation to one another. The covariance of two stocks (stock X, stock Y) is calculated using the following equation:\n",
    "\n",
    "\\begin{align*}\n",
    "COV(X,Y)=\\frac{\\sum(x_i-\\overline{X})\\times(y_i-\\overline{Y})}{N}\n",
    "\\end{align*}\n",
    "\n",
    "We will store the results of the covariance calculations in 'cov_matrix'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = percent_change.cov()\n",
    "\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Deviation\n",
    "\n",
    "To calculate standard deviation, we need to calculate the correlation between stocks.\n",
    "\n",
    "To do this, we will use a correlation matrix.\n",
    "\n",
    "The correlation of two stocks (stock X, stock Y) is calculated using the following equation:\n",
    "\n",
    "\\begin{align*}\n",
    "\\rho(X,Y)=\\frac{COV(X,Y)}{\\sigma_X \\sigma_Y}\n",
    "\\end{align*}\n",
    "\n",
    "Where $\\rho_{x,y}$ is the correlation between the two variables, $cov(r_x, r_y)$ is the covariance of return X and return Y, and $\\sigma_x$ and $\\sigma_y$ are the standard deviations of X and Y respectively.\n",
    "\n",
    "Note that each stock has a correlation of 1 with itself, a perfect positive correlation.\n",
    "\n",
    "There exists a positive correlation between stocks X and Y if $0 < \\rho_{x,y} < 1$.\n",
    "\n",
    "There exists a negative (inverse) correlation between stocks X and Y if $-1 < \\rho_{x,y} < 0$.\n",
    "\n",
    "There exists no (zero) correlation between stocks X and Y if $\\rho_{x,y} = 0$. In reality, it is almost impossible for two stocks to have zero correlation with each other.\n",
    "\n",
    "We will store the results of the correlation calculations in 'corr_matrix'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = percent_change.corr()\n",
    "\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Return\n",
    "Finally, we will calculate the expected return of each portfolio. The expected return of a portfolio is caluclated by the equation below:\n",
    "\n",
    "\\begin{align*}\n",
    "E(X)=\\overline{X}=\\frac{\\sum x_i}{N}\n",
    "\\end{align*}\n",
    "\n",
    "where $x_i$ are individual returns of some security $X$, $N$ is the total number of observations (time periods for us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Volatility**\n",
    "\n",
    "We now want to calculate the yearly volatility rate of each stock (which is equivalent to the annual standard deviation). Through this calculation, we know which stocks have the highest price fluctuations, or essentially, which stocks are the riskiest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate Yearly Expected Returns (Returns)\n",
    "\n",
    "closing_prices.index = pd.to_datetime(closing_prices.index)\n",
    "\n",
    "individual_expected_returns = closing_prices.resample(\"Y\").first().pct_change().mean()\n",
    "\n",
    "yearly_stats = pd.DataFrame(individual_expected_returns, columns=[\"Returns\"])\n",
    "\n",
    "# Calculate Annual Standard Deviation (Volatility)\n",
    "\n",
    "trading_days = 250\n",
    "\n",
    "annual_standard_deviation = percent_change.std().apply(\n",
    "    lambda x: x * np.sqrt(trading_days)\n",
    ")\n",
    "\n",
    "yearly_stats[\"Volatility\"] = annual_standard_deviation\n",
    "\n",
    "yearly_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we sort the stocks and their annual volatility rates in increasing order and take the first twenty tickers if there are 20 or more tickers total, otherwise we use all the stocks. We do this because we want the stocks with the lowest volatility rates so that we can create the least risky portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_volatility = yearly_stats.sort_values(\"Volatility\")\n",
    "\n",
    "lowest_volatility_tickers = list(\n",
    "    sorted_volatility[\"Volatility\"][\n",
    "        0 : (20 if len(yearly_stats) > 20 else len(yearly_stats))\n",
    "    ].index\n",
    ")\n",
    "\n",
    "yearly_stats = yearly_stats.loc[lowest_volatility_tickers]\n",
    "\n",
    "cov_matrix = cov_matrix.loc[lowest_volatility_tickers][lowest_volatility_tickers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate 10000 random portfolios from the 20 tickers we chose (with lowest volatility). We then find the portfolio with the lowest volatility (the safest portfolio) and find the weightings for each stock that created the portfolio.\n",
    "\n",
    "Note: You can change this number to change the number of randomly generated portfolios. The more number of random portfolios generated, the more optimized the final optimized portfolio will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_portfolios = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate portfolios with random weights\n",
    "\n",
    "# generate_portfolios(tickers, number_of_portfolios) generates\n",
    "#   a collection of [number_of_portfolios] portfolios from the\n",
    "#   list of [tickers]\n",
    "\n",
    "\"\"\"\n",
    "Params:\n",
    "    tickers (listof Str): List of stock tickers to choose from\n",
    "    number_of_portfolios (Nat): Number of portfolios to generate\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_portfolios(tickers, number_of_portfolios):\n",
    "    weights = []\n",
    "    returns = []\n",
    "    volatility = []\n",
    "\n",
    "    for i in range(number_of_portfolios):\n",
    "        individual_weights = np.random.random(len(tickers))\n",
    "        individual_weights = individual_weights / np.sum(individual_weights)\n",
    "        weights.append(individual_weights)\n",
    "\n",
    "        individual_returns = np.dot(individual_weights, yearly_stats.Returns)\n",
    "        returns.append(individual_returns)\n",
    "\n",
    "        portfolio_variance = (\n",
    "            cov_matrix.mul(individual_weights, axis=0)\n",
    "            .mul(individual_weights, axis=1)\n",
    "            .sum()\n",
    "            .sum()\n",
    "        )\n",
    "        standard_deviation = np.sqrt(portfolio_variance)\n",
    "        individual_volatility = standard_deviation * np.sqrt(trading_days)\n",
    "        volatility.append(individual_volatility)\n",
    "\n",
    "    portfolios = pd.DataFrame(index=range(number_of_portfolios))\n",
    "\n",
    "    portfolios[\"Returns\"] = returns\n",
    "    portfolios[\"Volatility\"] = volatility\n",
    "\n",
    "    for i in range(len(tickers)):\n",
    "        for j in range(number_of_portfolios):\n",
    "            portfolios[tickers[i]] = weights[j][i]\n",
    "\n",
    "    return portfolios\n",
    "\n",
    "\n",
    "random_portfolios = generate_portfolios(lowest_volatility_tickers, number_of_portfolios)\n",
    "\n",
    "random_portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick optimal portfolio with individual stock weighting\n",
    "\n",
    "safest_portfolio = random_portfolios.iloc[random_portfolios.Volatility.idxmin()]\n",
    "\n",
    "pd.DataFrame(safest_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Efficient Frontier Graph\n",
    "\n",
    "plt.subplots(figsize=[10, 10])\n",
    "\n",
    "plt.scatter(\n",
    "    x=random_portfolios.Volatility, y=random_portfolios.Returns, s=10, alpha=0.7\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    safest_portfolio.Volatility, safest_portfolio.Returns, color=\"r\", marker=\"*\", s=200\n",
    ")\n",
    "\n",
    "plt.title(\"Efficient Frontier of Randomly Generated Portfolios\")\n",
    "plt.xlabel(\"Volatility\")\n",
    "plt.ylabel(\"Returns\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace date with Nov. 26, 2021 (format: 'YYYY-MM-DD')\n",
    "\n",
    "date = \"2021-11-26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce final list of chosen tickers and weights\n",
    "\n",
    "initial_capital = 100000\n",
    "\n",
    "current_day = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "\n",
    "next_day = current_day + timedelta(days=1)\n",
    "\n",
    "final_portfolio_columns = [\"Ticker\", \"Price\", \"Shares\", \"Value\", \"Weight\"]\n",
    "\n",
    "FinalPortfolio = pd.DataFrame(columns=final_portfolio_columns)\n",
    "\n",
    "safest_portfolio_data = safest_portfolio[2:]\n",
    "\n",
    "safest_portfolio_data = safest_portfolio_data.sort_index()\n",
    "\n",
    "safest_portfolio_tickers = list(safest_portfolio_data.index)\n",
    "\n",
    "safest_portfolio_weights = list(safest_portfolio_data.values)\n",
    "\n",
    "prices = yf.download(safest_portfolio_tickers, start=current_day, end=next_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prices = prices[\"Adj Close\"].loc[date]\n",
    "\n",
    "FinalPortfolio['Ticker'] = safest_portfolio_tickers\n",
    "\n",
    "FinalPortfolio['Price'] = current_prices.values\n",
    "\n",
    "FinalPortfolio['Weight'] = safest_portfolio_weights\n",
    "\n",
    "FinalPortfolio['Value'] = initial_capital * FinalPortfolio.Weight\n",
    "\n",
    "FinalPortfolio['Shares'] = FinalPortfolio.Value / FinalPortfolio.Price\n",
    "\n",
    "FinalPortfolio.index = list(range(1, 21))\n",
    "\n",
    "FinalPortfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "\n",
    "total_portfolio_value = FinalPortfolio.Value.sum().round(2)\n",
    "\n",
    "if total_portfolio_value == initial_capital:\n",
    "    print(f\"The portfolio's total value is ${initial_capital}\")\n",
    "\n",
    "total_weight = FinalPortfolio.Weight.sum().round(2)\n",
    "\n",
    "if total_weight == 1:\n",
    "    print(\"The portfolio's weights add up to 100%.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export FinalPortfolio Data to CSV\n",
    "\n",
    "Stocks = FinalPortfolio[['Ticker', 'Shares']]\n",
    "\n",
    "Stocks.to_csv(\"Stocks_Group_3.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Data Analysis ###\n",
    "\n",
    "Our strategy was to generate a list of the top 20 least volatile stocks from the beginning of 2018 to late 2021. The reason why we chose the maximum number of 20 stocks is because, as we learned in class, splitting a portfolio over more stocks reduces the portfolio's risk.  \n",
    "\n",
    "After constructing our Efficient Frontier graph, with 10000 possible portfolios, our program selects the portfolio with the lowest volatility (the portfolio closest to the left). Since our strategy is to be safe (ie. generate a portfolio that gives us an \"ending value\" closest to zero), we decided to choose the portfolio with the lowest volatility because that should theoretically be the least risky and exported it as a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Derek, Yuqian, Jeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "Image Link: https://www.cryptimi.com/guides/is-diversification-the-right-strategy-for-your-cryptocurrency-portfolio\n",
    "\n",
    "Equations: Professor Thompson's notes\n",
    "\n",
    "\n",
    "Definition of MPT & EF: https://www.investopedia.com/terms/e/efficientfrontier.asp https://www.investopedia.com/terms/m/modernportfoliotheory.asp\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e28298bb47a08697a860182f4406c1126f813946b24568f02bad9bcf7ea902f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
